Metadata-Version: 2.1
Name: vqvae
Version: 0.0.0
Summary: PyTorch implementation of VQ-VAE
License: MIT
Keywords: pytorch,vq-vae,vqvae,vector-quantized-vae,vector-quantized-autoencoder
Classifier: Development Status :: 5 - Production/Stable
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.7
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Requires-Python: <3.10,>=3.7
Description-Content-Type: text/markdown
Requires-Dist: torch (>=1.8)
Requires-Dist: pytorch-lightning (>=1.8)
Requires-Dist: torchvision
Requires-Dist: tensorguard (==1.0.0)
Provides-Extra: dev
Requires-Dist: pytest ; extra == 'dev'

# Pytorch VQVAE implementation

## Example

```python
from vqvae import VQVAE, sequential_encoder, sequential_decoder
from torch.optim import  Adam
from functools import partial

input_channels = 3
output_channels = 3
embedding_length = 256
hidden_channels = 64
beta = 0.25
embedding_size = 512
opt = partial(Adam, lr=2e-4)

encoder = sequential_encoder(input_channels, embedding_size, hidden_channels)  # Encoder from the paper
decoder = sequential_decoder(embedding_size, output_channels, hidden_channels)  # Decoder from the paper
vqvae = VQVAE(encoder, decoder, opt, beta, embedding_length, embedding_size)  # Pytorch-Lightning module, 
                                                                              # hence usable to train the model

```
