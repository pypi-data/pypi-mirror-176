name: Extract

on:
  schedule:
    - cron: "0 0 * * *"
  workflow_dispatch:

concurrency:
  group: extract
  cancel-in-progress: true

jobs:
  # download-items:
  #   name: Download items
  #   runs-on: ubuntu-latest
  #   steps:
  #     - id: checkout
  #       name: Checkout
  #       uses: actions/checkout@v3

  #     - id: install
  #       name: Install Python dependencies
  #       uses: ./.github/actions/install

  #     - id: configure-git
  #       name: Configure git
  #       run: |
  #         git config --global user.name "GitHub Actions"
  #         git config --global user.email "actions@github.com"
  #         git config pull.rebase false
  #         git pull origin $GITHUB_REF

  #     - id: download-items
  #       name: Download items
  #       run: |
  #         pipenv run python -m newshomepages.extract download-items --output-path=./_dist/
  #         git pull origin $GITHUB_REF
  #         cp ./_dist/*.json extracts/json/
  #         git add ./extracts/json
  #         git commit -m "Update archive.org items" --author="palewire <palewire@users.noreply.github.com>" && git push || true
  #       shell: bash
  #       env:
  #         IA_ACCESS_KEY: ${{ secrets.IA_ACCESS_KEY }}
  #         IA_SECRET_KEY: ${{ secrets.IA_SECRET_KEY }}
  #         IA_COLLECTION: ${{ secrets.IA_COLLECTION }}

  #     - id: consolidate-items
  #       name: Consolidate items
  #       run: |
  #         pipenv run python -m newshomepages.extract consolidate
  #         git pull origin $GITHUB_REF
  #         git add ./extracts
  #         git commit -m "Update consolidated extracts" --author="palewire <palewire@users.noreply.github.com>" && git push || true
  #       shell: bash

  #     - id: save
  #       name: Save artifact
  #       uses: actions/upload-artifact@v3
  #       with:
  #         name: extracts
  #         path: ./extracts
  #         if-no-files-found: error

  download-lighthouse:
    name: Download Lighthouse
    runs-on: ubuntu-latest
    steps:
      - id: checkout
        name: Checkout
        uses: actions/checkout@v3

      - id: install
        name: Install
        uses: ./.github/actions/install

      - id: get-latest
        name: Get latest data
        run: |
          git config --global user.name "GitHub Actions"
          git config --global user.email "actions@github.com"
          git config pull.rebase false
          git pull origin $GITHUB_REF

      - id: cache
        name: Update cache
        uses: actions/cache@v3
        with:
          path: .cache
          key: extract-lighthouse-${{ github.run_id }}
          restore-keys: |
            extract-lighthouse

      - id: download-lighthouse
        name: Download Lighthouse files
        run: pipenv run python -m newshomepages.extract download-lighthouse --days=7 --output-path=./extracts/csv/lighthouse-sample.csv;
        shell: bash

      - id: commit
        name: Commit
        run: |
          git pull origin $GITHUB_REF
          git add ./extracts
          git commit -m "Update Lighthouse sample" --author="palewire <palewire@users.noreply.github.com>" && git push || true
        shell: bash

      - id: save
        name: Save artifact
        uses: actions/upload-artifact@v3
        with:
          name: extracts
          path: ./extracts
          if-no-files-found: error

  download-drudge-hyperlinks:
    name: Download Drudge hyperlinks
    runs-on: ubuntu-latest
    steps:
      - id: checkout
        name: Checkout
        uses: actions/checkout@v3

      - id: install
        name: Install
        uses: ./.github/actions/install

      - id: get-latest
        name: Get latest data
        run: |
          git config --global user.name "GitHub Actions"
          git config --global user.email "actions@github.com"
          git config pull.rebase false
          git pull origin $GITHUB_REF

      - id: cache
        name: Update cache
        uses: actions/cache@v3
        with:
          path: .cache
          key: extract-drudge-${{ github.run_id }}
          restore-keys: |
            extract-drudge

      - id: download-drudge-items
        name: Download Drudge items
        run: pipenv run python -m newshomepages.extract download-items --site=drudge
        shell: bash
        env:
          IA_ACCESS_KEY: ${{ secrets.IA_ACCESS_KEY }}
          IA_SECRET_KEY: ${{ secrets.IA_SECRET_KEY }}
          IA_COLLECTION: ${{ secrets.IA_COLLECTION }}

      - id: consolidate-items
        name: Consolidate items
        run: pipenv run python -m newshomepages.extract consolidate
        shell: bash

      - id: download-drudge-hyperlinks
        name: Download Drudge hyperlink lists
        run: pipenv run python -m newshomepages.extract download-hyperlinks --site=drudge --days=90 --output-path=./extracts/csv/drudge-hyperlinks-sample.csv;
        shell: bash

      - id: commit
        name: Commit
        run: |
          git pull origin $GITHUB_REF
          git add ./extracts
          git commit -m "Update Drudge hyperlinks sample" --author="palewire <palewire@users.noreply.github.com>" && git push || true
        shell: bash

      - id: save
        name: Save artifact
        uses: actions/upload-artifact@v3
        with:
          name: extracts
          path: ./extracts
          if-no-files-found: error

  # download-us-right-wing-hyperlinks:
  #   name: Download U.S. right wing hyperlinks
  #   runs-on: ubuntu-latest
  #   steps:
  #     - id: checkout
  #       name: Checkout
  #       uses: actions/checkout@v3

  #     - id: install
  #       name: Install
  #       uses: ./.github/actions/install

  #     - id: get-latest
  #       name: Get latest data
  #       run: |
  #         git config --global user.name "GitHub Actions"
  #         git config --global user.email "actions@github.com"
  #         git config pull.rebase false
  #         git pull origin $GITHUB_REF

  #     - id: cache
  #       name: Update cache
  #       uses: actions/cache@v3
  #       with:
  #         path: .cache
  #         key: extract-us-right-wing-hyperlinks-${{ github.run_id }}
  #         restore-keys: |
  #           extract-us-right-wing-hyperlinks

  #     - id: download-us-right-wing-items
  #       name: Download U.S. right wing items
  #       run: pipenv run python -m newshomepages.extract download-items --bundle=us-right-wing
  #       shell: bash
  #       env:
  #         IA_ACCESS_KEY: ${{ secrets.IA_ACCESS_KEY }}
  #         IA_SECRET_KEY: ${{ secrets.IA_SECRET_KEY }}
  #         IA_COLLECTION: ${{ secrets.IA_COLLECTION }}

  #     - id: consolidate-items
  #       name: Consolidate items
  #       run: pipenv run python -m newshomepages.extract consolidate
  #       shell: bash

  #     - id: download-us-right-wing-hyperlinks
  #       name: Download U.S. right wing hyperlink lists
  #       run: pipenv run python -m newshomepages.extract download-hyperlinks --bundle=us-right-wing --days=7 --output-path=./extracts/csv/us-right-wing-hyperlinks-sample.csv;
  #       shell: bash

  #     - id: commit
  #       name: Commit
  #       run: |
  #         git pull origin $GITHUB_REF
  #         git add ./extracts
  #         git commit -m "Update U.S. right wing hyperlinks sample" --author="palewire <palewire@users.noreply.github.com>" && git push || true
  #       shell: bash

  #     - id: save
  #       name: Save artifact
  #       uses: actions/upload-artifact@v3
  #       with:
  #         name: extracts
  #         path: ./extracts
  #         if-no-files-found: error

  publish:
    name: Publish
    runs-on: ubuntu-latest
    timeout-minutes: 60
    continue-on-error: true
    needs: [download-lighthouse, download-drudge-hyperlinks, download-us-right-wing-hyperlinks]
    steps:
      - id: checkout
        name: Checkout
        uses: actions/checkout@v3

      - id: upload
        name: Upload
        uses: ./.github/actions/upload
        with:
          artifact: extracts
          destination: extracts
          s3-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          s3-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          s3-bucket-name: ${{ secrets.AWS_BUCKET_NAME }}
